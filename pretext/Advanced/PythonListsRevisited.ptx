<?xml version="1.0"?>
<section xml:id="advanced_python-lists-revisited">
  <title>Python Lists Revisited</title>
  <p>In <xref ref="chapter-analysis" /> we introduced some Big-O
            performance limits on Python's list data type. However, we did not yet
            have the knowledge necessary to understand how Python implements its
            list data type. in
            <xref ref="basic-data-structures"/> you learned
            how to implement a linked list using the nodes and references pattern.
            However, the nodes and references implementation still did not match the
            performance of the Python list. In this section we will look at the
            principles behind the Python list implementation. It is important to
            recognize that this implementation is not going to be the same as
            Python's since the real Python list is implemented in the C programming
            language. The idea in this section is to use Python to demonstrate the
            key ideas, not to replace the C implementation.</p>
  <p>The key to Python's implementation of a list is to use a data type
            called an <em>array</em> common to C, C++, Java, and many other programming
            languages. The array is very simple and is only capable of storing one
            kind of data. For example, you could have an array of integers or an
            array of floating point numbers, but you cannot mix the two in a single
            array. The array only supports two operations: indexing and assignment
            to an array index.</p>
  <p>The best way to think about an array is that it is one continuous block
            of bytes in the computer's memory. This block is divided up into <m>n</m>-byte
            chunks where <m>n</m> is based on the data type that is stored in the array.
            <xref href="fig-array" /> illustrates the idea of an array that is sized
            to hold six floating point values.</p>
  <figure align="" xml:id="fig-array">
    <caption>An Array of Floating Point Numbers</caption>
    <image source="Advanced/Figures/array.png" width="50%" alt="An Array of Floating Point Numbers"/>
  </figure>
  <p>In Python, each floating point number uses 16 <footnote_reference docname="Advanced/PythonListsRevisited" xml:id="advanced_id1" refid="id3">1</footnote_reference> bytes of memory. So
            the array in <xref ref="fig-array" /> uses a total of 96 <footnote_reference docname="Advanced/PythonListsRevisited" xml:id="advanced_id2" refid="id4">2</footnote_reference> bytes.
            The base address is the location in memory where the array starts. You
            have seen addresses before in Python for different objects that you have
            defined. For example: <c>&lt;__main__.Foo object at 0x5eca30&gt;</c> shows that
            the object <c>Foo</c> is stored at memory address <c>0x5eca30</c>. The address
            is very important because an array implements the index operator using a
            very simple calculation:</p>
  <pre>item_address = base_address + index * size_of_object</pre>
  <p>For example, suppose that our array starts at location <c>0x000040</c>,
            which is 64 in decimal. To calculate the location of the object at
            position 4 in the array we simply do the arithmetic:
            <m>64 + 4 \cdot 8 = 96</m>. Clearly this kind of calculation is
            <m>O(1)</m>. Of course this comes with some risks. First, since
            the size of an array is fixed, one cannot just add things on to the end of
            the array indefinitely without some serious consequences. Second, in
            some languages, like C, the bounds of the array are not even checked, so
            even though your array has only six elements in it, assigning a value
            to index 7 will not result in a runtime error. As you might imagine this can
            cause big problems that are hard to track down. In the Linux operating
            system, accessing a value that is beyond the boundaries of an array will
            often produce the rather uninformative error message <q>segmentation
            violation.</q></p>
  <p>The general strategy that Python uses to implement a linked list using
            an array is as follows:</p>
  <p>
    <ul>
      <li>
        <p>Python uses an array that holds references (called <em>pointers</em> in C) to
                    other objects.</p>
      </li>
      <li>
        <p>Python uses a strategy called <em>over-allocation</em> to allocate an
                    array with space for more objects than is needed initially.</p>
      </li>
      <li>
        <p>When the initial array is finally filled up, a new, bigger array is
                    over-allocated and the contents of the old array are copied to the
                    new array.</p>
      </li>
    </ul>
  </p>
  <p>The implications of this strategy are pretty amazing. Let's look at what
            they are first before we dive into the implementation or prove anything.</p>
  <p>
    <ul>
      <li>
        <p>Accessing an itema at a specific location is <m>O(1)</m>.</p>
      </li>
      <li>
        <p>Appending to the list is <m>O(1)</m> on average, but <m>O(n)</m> in
                    the worst case.</p>
      </li>
      <li>
        <p>Popping from the end of the list is <m>O(1)</m>.</p>
      </li>
      <li>
        <p>Deleting an item from the list is <m>O(n)</m>.</p>
      </li>
      <li>
        <p>Inserting an item into an arbitrary position is <m>O(n)</m>.</p>
      </li>
    </ul>
  </p>
  <p>Let's look at how the strategy outlined above works for a very simple
            implementation. To begin, we will only implement the constructor, a
            <c>__resize</c> method, and the <c>append</c> method. We will call this class
            <c>ArrayList</c>. In the constructor we will need to initialize two
            instance variables. The first will keep track of the size of the current
            array; we will call this <c>max_size</c>. The second instance variable will
            keep track of the current end of the list; we will call this one
            <c>last_index</c>. Since Python does not have an array data type, we will
            use a list to simulate an array.
            Listing&#xA0;<xref ref="lst_arraylistinit" /> contains the code
            for the first three methods of <c>ArrayList</c>. Notice that the
            constructor method initializes the two instance variables described
            above and then creates a zero element array called <c>my_array</c>. The
            constructor also creates an instance variable called <c>size_exponent</c>.
            We will understand how this variable is used shortly.</p>
  <listing xml:id="lst_arraylistinit">
  <program language="python">
  <input>
  class ArrayList:
    def __init__(self):
        self.size_exponent = 0
        self.max_size = 0
        self.last_index = 0
        self.my_array = []

    def append(self, val):
        if self.last_index &gt; self.max_size - 1:  |\label{line:lst_arr_size}|
            self.__resize()
        self.my_array[self.last_index] = val
        self.last_index += 1

    def __resize(self):
        new_size = 2 ** self.size_exponent
        print("new_size = ", new_size)
        new_array = [0] * new_size
        for i in range(self.max_size):  |\label{line:lst_arr_cop1}|
            new_array[i] = self.my_array[i]

        self.max_size = new_size
        self.my_array = new_array
        self.size_exponent += 1
  </input>
  </program>
  </listing>
  <p>Next, we will implement the <c>append</c> method. The first thing <c>append</c>
            does is test for
            the condition where <c>last_index</c> is greater than the number of
            available index positions in the array (line&#xA0; <!-- <url href="#line:lst_arr_size" visual="#line:lst_arr_size">[line:lst_arr_size]</url> -->).
            If this is the case then
            <c>__resize</c> is called. Notice that we are using the double underscore
            convention to make the <c>resize</c> method private. Once the array is resized
            the new value is added to the list at <c>last_index</c>, and <c>last_index</c>
            is incremented by one.</p>
  <p>The <c>resize</c> method calculates a new size for the array using
            <m>2 ^ {size\_exponent}</m>. There are many methods that could be used
            for resizing the array. Some implementations double the size of the
            array every time as we do here, some use a multiplier of 1.5, and some
            use powers of two. Python uses a multiplier of 1.125 plus a constant.
            The Python developers designed this strategy as a good tradeoff for
            computers of varying CPU and memory speeds. The Python strategy leads to
            a sequence of array sizes of <m>0, 4, 8, 16, 24, 32, 40, 52, 64, 76\ldots</m> .
            Doubling the array size leads to a bit more wasted space at any
            one time, but is much easier to analyze. Once a new array has been
            allocated, the values from the old list must be copied into the new
            array; this is done in the loop starting on
            line&#xA0; <!--<url href="#line:lst_arr_cop1" visual="#line:lst_arr_cop1">[line:lst_arr_cop1]</url>. --> Finally the values
            <c>max_size</c> and <c>last_index</c> must be updated, <c>size_exponent</c> must
            be incremented, and <c>new_array</c> is saved as <c>self.my_array</c>. In a
            language like C the old block of memory referenced by <c>self.my_array</c>
            would be explicitly returned to the system for reuse. However, recall
            that in Python objects that are no longer referenced are automatically
            cleaned up by the garbage collection algorithm.</p>
  <p>Before we move on let's analyze why this strategy gives us an average
            <m>O(1)</m> performance for <c>append</c>. The key is to notice that most
            of the time the cost to append an item <m>c_i</m> is 1. The only time
            that the operation is more expensive is when <c>last_index</c> is a power
            of 2. When <c>last_index</c> is a power of 2 then the cost to append an
            item is <m>O(last\_index)</m>. We can summarize the cost to insert the
            <m>i_{th}</m> item as follows:</p>
  <md>c_i =
\begin{cases}
  <mrow>i \text{ if } i \text{ is a power of 2} </mrow>
  <mrow>1 \text{ otherwise}</mrow>
\end{cases}</md>
  <p>Since the expensive cost of copying <c>last_index</c> items occurs
            relatively infrequently we spread the cost out, or <em>amortize</em>, the
            cost of insertion over all of the appends. When we do this the cost of
            any one insertion averages out to <m>O(1)</m>. For example, consider
            the case where you have already appended four items. Each of these four
            appends costs you just one operation to store in the array that was
            already allocated to hold four items. When the fifth item is added a new
            array of size 8 is allocated and the four old items are copied. But now
            you have room in the array for four additional low cost appends.
            Mathematically we can show this as follows:</p>
  <md>\begin{aligned}
  <mrow>cost_{total} &amp;= n + \sum_{j=0}^{\log_2{n}}{2^j}  </mrow>
  <mrow>          &amp;= n + 2n </mrow>
  <mrow>          &amp;= 3n</mrow>
  \end{aligned}
  </md>
  <p>The summation in the previous equation may not be obvious to you, so
      let's think about that a bit more. The sum goes from zero to <m>\log_2{n}</m>.
            The upper bound on the summation tells us how many times we
            need to double the size of the array. The term <m>2^j</m> accounts for
            the copies that we need to do when the array is doubled. Since the total
            cost to append n items is <m>3n</m>, the cost for a single item is
            <m>3n/n = 3</m>. Because the cost is a constant we say that it is
            <m>O(1)</m>. This kind of analysis is called <term>amortized analysis</term> and
            is very useful in analyzing more advanced algorithms.</p>
  <p>Next, let us turn to the index operators.
            Listing&#xA0;<xref ref="lst_arrindex" /> shows our Python
            implementation for index and assignment to an array location. Recall
            that we discussed above that the calculation required to find the memory
            location of the <m>i_{th}</m> item in an array is a simple <m>O(1)</m>
            arithmetic expression. Even languages like C hide that calculation
            behind a nice array index operator, so in this case the C and the Python
            look very much the same. In fact, in Python it is very difficult to get
            the actual memory location of an object for use in a calculation like
            this so we will just rely on list's built-in index operator. To confirm this,
            you can always get the Python source code and look at
            the file <c>listobject.c</c>.</p>
  <listing xml:id="lst_arrindex">
  <program language="python">
  <input>
def __getitem__(self, idx):
    if idx &lt; self.last_index:
        return self.my_array[idx]
    raise LookupError("index out of bounds")

def __setitem__(self, idx, val):
    if idx &lt; self.last_index:
        self.my_array[idx] = val
    raise LookupError("index out of bounds")
  </input>
  </program>
  </listing>
  <p>Finally, let's take a look at one of the more expensive list operations,
            insertion. When we insert an item into an <c>ArrayList</c> we will need to
            first shift everything in the list at the insertion point and beyond
            ahead by one index position in order to make room for the item we are
            inserting. The process is illustrated in <xref ref="fig-arrlistins" />.</p>
  <figure align="" xml:id="fig-arrlistins">
    <caption xmlns:c="https://www.sphinx-doc.org/" xmlns:changeset="https://www.sphinx-doc.org/" xmlns:citation="https://www.sphinx-doc.org/" xmlns:cpp="https://www.sphinx-doc.org/" xmlns:index="https://www.sphinx-doc.org/" xmlns:js="https://www.sphinx-doc.org/" xmlns:math="https://www.sphinx-doc.org/" xmlns:py="https://www.sphinx-doc.org/" xmlns:rst="https://www.sphinx-doc.org/" xmlns:std="https://www.sphinx-doc.org/">Inserting 27.1 at Index 2 in an ArrayList</caption>
    <image source="Advanced/Figures/insertArray.png" width="50%" alt="Inserting 27.1 at index 2 in an ArrayList"/>
  </figure>
  <p>The key to implementing <c>insert</c> correctly is to realize that as you
            are shifting values in the array you do not want to overwrite any
            important data. The way to do this is to work from the end of the list
            back toward the insertion point, copying data forward. Our implementation
            of <c>insert</c> is shown in
            <xref ref="lst_arrlistins" />. Note how the <c>range</c> is
            set up on
            line&#xA0;<!-- <url href="#line:lst_arrlistins_range" visual="#line:lst_arrlistins_range">[line:lst_arrlistins_range]</url> --> to
            ensure that we are copying existing data into the unused part of the
            array first, and then subsequent values are copied over old values that
            have already been shifted. If the loop had started at the insertion
            point and copied that value to the next larger index position in the
            array, the old value would have been lost forever.</p>
  <pre>def insert(self, idx, val):
    if self.last_index &gt; self.max_size - 1:
        self.__resize()
    for i in range(self.last_index, idx - 1, -1):  |\label{line:lst_arrlistins_range}|
        self.my_array[i + 1] = self.my_array[i]
    self.last_index += 1
    self.my_array[idx] = val</pre>
  <p>The performance of the insert is <m>O(n)</m> since in the worst case we
            want to insert something at index 0 and we have to shift the entire
            array forward by one. On average we will only need to shift half of the
            array, but this is still <m>O(n)</m>. You may want to go back to
            <xref ref="basic-data-structures"/> and remind yourself how all of these
            list operations are done using nodes and references. Neither
            implementation is right or wrong; they just have different performance
            guarantees that may be better or worse depending on the kind of
            application you are writing. In particular, do you intend to add items
            to the beginning of the list most often, or does your application add
            items to the end of the list? Will you be deleting items from the list
            or only adding new items to the list?</p>
  <p>There are several other interesting operations that we have not yet
            implemented for our <c>ArrayList</c> including: <c>pop</c>, <c>del</c>,
            <c>index</c>, and making the <c>ArrayList</c> iterable. We leave these
            enhancements to the <c>ArrayList</c> as an exercise for you.</p>
<!--
  <footnote backrefs="id1" docname="Advanced/PythonListsRevisited" xml:id="advanced_id3" names="1">
    <label>1</label>
    <p>8 bytes reference count + 8 bytes pointer to the type object + 8
                bytes of data = 24</p>
  </footnote>
  <footnote backrefs="id2" docname="Advanced/PythonListsRevisited" xml:id="advanced_id4" names="2">
    <label>2</label>
    <p>sys.getsizeof([3.1415, 2.189, 0.0, 0.0, 9.87]) is 104</p>
  </footnote>
-->
</section>
